{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import xlwings as xw\n",
    "from rapidfuzz import fuzz, process\n",
    "from pathlib import Path\n",
    "from docxtpl import DocxTemplate\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from pathlib import Path\n",
    "import rapidfuzz\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz\n",
    "from rapidfuzz.process import extractOne\n",
    "import datetime \n",
    "from pathlib import Path\n",
    "from docxtpl import DocxTemplate\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "import subprocess\n",
    "from tkinter import filedialog\n",
    "from tkinter import Tk\n",
    "import win32com.client as win32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A GENERIC FUNCTIONS\n",
    "\n",
    "#A.1 Closest Match btw string and dataframe Headers\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "def closest_match_df(string, df):\n",
    "    column_names = df.columns.tolist()\n",
    "    \n",
    "    # Using rapidfuzz process to find the closest match\n",
    "    closest_match = process.extractOne(string, column_names)\n",
    "    \n",
    "    # Getting the column index of the closest match\n",
    "    closest_match_index = column_names.index(closest_match[0])\n",
    "            \n",
    "    return closest_match_index\n",
    "\n",
    "\n",
    "#A.2 Find Closest Match btw a query and list of dictionaries but pass cutoff\n",
    "def find_closest_match(query, list_of_dicts, score_cutoff=90):\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    best_result = None\n",
    "    \n",
    "    for dict_item in list_of_dicts:\n",
    "        if 'Field Description' in dict_item:  # Make sure 'Field Description' key exists\n",
    "            score = fuzz.ratio(query, dict_item['Field Description'])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = dict_item['Field Description']\n",
    "                best_result = dict_item['Result'] if 'Result' in dict_item else None\n",
    "\n",
    "    if best_score >= score_cutoff:\n",
    "        return best_match, best_result\n",
    "    else:\n",
    "        return 'Not Found', None\n",
    "\n",
    "#A.3 Find Closest Folder\n",
    "def find_client_folder(Ref_No, folder_prefix, folder_1_suffix, folder_2_suffix, folder_3_suffix):\n",
    "    folder_names = [folder_1_suffix, folder_2_suffix, folder_3_suffix]\n",
    "    for folder_suffix in folder_names:\n",
    "        folder_path = os.path.join(folder_prefix, folder_suffix)\n",
    "        for subfolder in os.listdir(folder_path):\n",
    "            if Ref_No in subfolder:\n",
    "                return os.path.join(folder_path, subfolder)\n",
    "    return None\n",
    "\n",
    "#A.4 Create Folder\n",
    "def create_folder(Last_Name, First_Name, Ref_No):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    folder_path = filedialog.askdirectory()\n",
    "    new_folder_name = f\"{Last_Name}.{First_Name}.[{Ref_No}]\"\n",
    "    new_folder_path = os.path.join(folder_path, new_folder_name)\n",
    "    os.mkdir(new_folder_path)\n",
    "    return new_folder_path\n",
    "\n",
    "#A.5 Find or Create Folder\n",
    "def find_or_create_folder(Last_Name, First_Name, Ref_No, folder_prefix, folder_1_suffix, folder_2_suffix, folder_3_suffix):\n",
    "    client_folder_path = find_client_folder(Ref_No, folder_prefix, folder_1_suffix, folder_2_suffix, folder_3_suffix)\n",
    "    if client_folder_path is None:\n",
    "        #print(\"Unable to find the client folder.\")\n",
    "        #print(\"1: Create a folder\")\n",
    "        #print(\"2: Pick a current folder\")\n",
    "        option = input(\"Choose an option: \")\n",
    "        if option == \"1\":\n",
    "            client_folder_path = create_folder(Last_Name, First_Name, Ref_No)\n",
    "        elif option == \"2\":\n",
    "            root = tk.Tk()\n",
    "            root.withdraw()\n",
    "            client_folder_path = filedialog.askdirectory()\n",
    "    return client_folder_path\n",
    "\n",
    "#A.6 Get Subdirectories\n",
    "def get_subdirectories(directory):\n",
    "    return [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]\n",
    "\n",
    "#A.8 \n",
    "def remove_text_in_brackets(df):\n",
    "    for col in df.columns:\n",
    "        if 'Company' in col:\n",
    "            if df[col].iloc[0] not in [0, '']:\n",
    "                df[col] = df[col].str.replace(r'\\[.*\\]', '')\n",
    "    return df\n",
    "\n",
    "#A.9 Ordinal\n",
    "def ordinal(n):\n",
    "    suffix = [\"th\", \"st\", \"nd\", \"rd\"]\n",
    "    if n < 0:\n",
    "        return str(n)\n",
    "    elif n % 100 in [11, 12, 13]:  # special case\n",
    "        return str(n) + \"th\"\n",
    "    else:\n",
    "        return str(n) + suffix[n % 10 if n % 10 < 4 else 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Define Sheets, Tables, dfs\n",
    "def defineshtb():\n",
    "    # 1.1: Retrieve currently active workbook and its path\n",
    "    currentwb = xw.books.active\n",
    "    original_excel_path = currentwb.fullname    \n",
    "    \n",
    "    # 1.2: Define current timestamp and parent folder\n",
    "    current_datetime = datetime.datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    currentpath = Path(original_excel_path)\n",
    "    parent_folder = currentpath.parent    \n",
    "    #print(parent_folder)\n",
    "          \n",
    "    # 1.5 Define Sheets\n",
    "    shcalcs_pc = currentwb.sheets['calcs_pc']\n",
    "\n",
    "    shCalcs = currentwb.sheets['Calcs']\n",
    "    shLists = currentwb.sheets['Lists']\n",
    "    shDDCTemplates = currentwb.sheets['DDCTemplates']\n",
    "    shInvestTemplates = currentwb.sheets['InvestTemplates']\n",
    "    shSTTemplates = currentwb.sheets['STTemplates']\n",
    "    shMedGapTemplates = currentwb.sheets['MedGapTemplates']\n",
    "    shStart = currentwb.sheets['Start']\n",
    "    shhdr_col_static = currentwb.sheets['hdr_col_static']\n",
    "    shUserMapping = currentwb.sheets['UserMapping']\n",
    "    \n",
    "    # 1.16 Convert each table range to a DataFrame\n",
    "    tbTemplList = shLists.tables['tbTemplList']\n",
    "    tbFieldList = shLists.tables['tbFieldList']\n",
    "    tb_calc_pc = shCalcs.tables['tb_calc_pc']\n",
    "    \n",
    "    df_tbTemplList = pd.DataFrame(tbTemplList.range.value[1:], columns=tbTemplList.range.value[0])\n",
    "    df_tbFieldList = pd.DataFrame(tbFieldList.range.value[1:], columns=tbFieldList.range.value[0])\n",
    "    df_tb_calc_pc = pd.DataFrame(tb_calc_pc.range.value[1:], columns=tb_calc_pc.range.value[0])\n",
    "    \n",
    "    df_import_pc = shStart.range('A1').options(pd.DataFrame, expand='table', header=False).value\n",
    "    header = df_import_pc.iloc[0]\n",
    "    df_import_pc = df_import_pc[1:]\n",
    "    df_import_pc.columns = header\n",
    "    # Reset the index\n",
    "    df_import_pc = df_import_pc.reset_index(drop=True)\n",
    "    #print(df_import_pc.head())\n",
    "    \n",
    "    df_hdr_col_static = shhdr_col_static.range(\"A1\").options(pd.DataFrame, expand=\"table\").value\n",
    "    \n",
    "    return (\n",
    "        current_datetime, shUserMapping, parent_folder, shhdr_col_static, df_hdr_col_static, df_tb_calc_pc, df_import_pc, currentwb, shcalcs_pc,\n",
    "        shCalcs, shLists, shDDCTemplates, shInvestTemplates, shSTTemplates, shMedGapTemplates, shStart,\n",
    "        tbTemplList, tbFieldList, df_tbTemplList, df_tbFieldList\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "def defineusermapping(shUserMapping, currentwb, shStart, shCalcs):\n",
    "    Ref_No = shStart.range('A2').value\n",
    "    user = xw.apps.active.api.UserName\n",
    "    user_column = shUserMapping.range('A:A').options(transpose=True).value   \n",
    "    # Find the client folder prefix corresponding to the current user\n",
    "    user_index = next((i for i, name in enumerate(user_column) if name == user), None)\n",
    "   \n",
    "   # Retrieve the client folder prefix, user_excel_template_suffix and user_word_template_suffix if found, otherwise use default values\n",
    "    if user_index is not None:\n",
    "       folder_prefix = shUserMapping.range(f'B{user_index+1}').value\n",
    "       user_word_template_suffix = shUserMapping.range(f'C{user_index+1}').value\n",
    "       folder_1_suffix = shUserMapping.range(f'D{user_index+1}').value\n",
    "       folder_2_suffix = shUserMapping.range(f'E{user_index+1}').value\n",
    "       folder_3_suffix = shUserMapping.range(f'F{user_index+1}').value\n",
    "       shUserMapping.range('F2').value = folder_prefix\n",
    "    else:\n",
    "       folder_prefix = 'default_prefix'\n",
    "       user_word_template_suffix = 'default_word_suffix'\n",
    "       folder_1_suffix = 'default_suffix_1'\n",
    "       folder_2_suffix = 'default_suffix_2'\n",
    "       folder_3_suffix = 'default_suffix_3'    \n",
    "\n",
    "    # Prepare the user_word_search_string\n",
    "    user_word_search_string = folder_prefix + user_word_template_suffix\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(user_word_search_string):\n",
    "        # If not, prompt the user to select a template\n",
    "        root = Tk()\n",
    "        root.withdraw()  # we don't want a full GUI, so keep the root window from appearing\n",
    "        user_word_template = filedialog.askopenfilename()  # show an \"Open\" dialog box and return the path to the selected file\n",
    "        root.destroy()\n",
    "    else:\n",
    "        user_word_template = user_word_search_string  # Use the default template\n",
    "        \n",
    "    shCalcs.range('E2').value = user_word_template\n",
    "\n",
    "    return Ref_No, folder_prefix, user_word_template, folder_1_suffix, folder_2_suffix, folder_3_suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Define and manage DDC Contracts\n",
    "def No_of_Contracts(df_import_pc, currentwb, shDDCTemplates, shLists):\n",
    "    # assume df is your DataFrame with multiple columns\n",
    "    df_Death_RC_Contracts = df_import_pc.loc[:, df_import_pc.columns.str.contains('rc', case=False) & df_import_pc.columns.str.contains('category', case=False)]\n",
    "    df_Death_RC_Contracts.head()\n",
    "    count_Death_in_rows = df_Death_RC_Contracts.apply(lambda row: row.astype(str).str.contains('death', case=False).sum(), axis=1).sum()\n",
    "    # List the column header names of the columns where the values contain \"death\"\n",
    "    columns_with_death = [column for column in df_Death_RC_Contracts.columns if any(df_Death_RC_Contracts[column].astype(str).str.contains('death', case=False))]\n",
    "\n",
    "    # Extract the number from the first column header name\n",
    "    first_rc_containing_death = re.search(r'RC(\\d+)', columns_with_death[0]).group(1)\n",
    "\n",
    "    # Extract the number from the second column header name if count_Death_in_rows > 1\n",
    "    if len(columns_with_death) > 1:\n",
    "        second_rc_containing_death = re.search(r'RC(\\d+)', columns_with_death[1]).group(1)\n",
    "    else:\n",
    "        second_rc_containing_death = \"NA\"\\\n",
    "            \n",
    "    # Extract the number from the 3 column header name if count_Death_in_rows > 1\n",
    "    if len(columns_with_death) > 3:\n",
    "        third_rc_containing_death = re.search(r'RC(\\d+)', columns_with_death[2]).group(1)\n",
    "    else:\n",
    "        third_rc_containing_death = \"NA\"\n",
    "        \n",
    "    df_IP_RC_Contracts = df_import_pc.loc[:, df_import_pc.columns.str.contains('rc', case=False) & df_import_pc.columns.str.contains('p2', case=False)]\n",
    "    \n",
    "    # Check if any valid numbers other than 0.0 exist in the DataFrame\n",
    "    has_income_protection = any(df_IP_RC_Contracts.iloc[:, 1:].apply(lambda x: any(pd.to_numeric(x, errors='coerce').fillna(0) != 0.0), axis=1))  \n",
    "     \n",
    "    if count_Death_in_rows > 0:\n",
    "        if count_Death_in_rows == 1:\n",
    "            ddc_template = 'tbDDC1'\n",
    "        elif count_Death_in_rows == 2:\n",
    "            ddc_template = 'tbDDC2'    \n",
    "        elif count_Death_in_rows == 3:\n",
    "            ddc_template = 'tbDDC3'        \n",
    "    else:\n",
    "        ddc_template = \"NA\"\n",
    "    #print(ddc_template)    \n",
    "    \n",
    "    shDDCTemplates.range('A2').value = ddc_template \n",
    "    shLists.range('I3').value = first_rc_containing_death\n",
    "    shLists.range('I152').value = second_rc_containing_death\n",
    "    shLists.range('I301').value = third_rc_containing_death    \n",
    "        \n",
    "    ddc_dict = {\n",
    "        \"first_rc\": {\"rc_no\": first_rc_containing_death},\n",
    "        \"second_rc\": {\"rc_no\": second_rc_containing_death},\n",
    "        \"third_rc\": {\"rc_no\": third_rc_containing_death}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    return count_Death_in_rows, columns_with_death, ddc_dict, has_income_protection, ddc_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "def extract_inv_number(column_name):\n",
    "    match = re.search(r'I/B(\\d+):', column_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"NA\"\n",
    "\n",
    "#3.2\n",
    "def closest_invmatch_df(s, df):\n",
    "    best_match = None\n",
    "    highest_score = 0\n",
    "    for col in df.columns:\n",
    "        score = fuzz.ratio(s, col)\n",
    "        if score > highest_score:\n",
    "            best_match = col\n",
    "            highest_score = score\n",
    "    return df.columns.get_loc(best_match) if highest_score > 80 else -1\n",
    "\n",
    "#3.3\n",
    "def no_inv_contracts(df_import_pc, currentwb, shInvestTemplates, shLists):\n",
    "    df_ib_inv_contracts = df_import_pc.loc[:, df_import_pc.columns.str.contains('i/b', case=False) & df_import_pc.columns.str.contains('category', case=False)]\n",
    "    df_ib_inv_contracts.head()\n",
    "    keywords = ['pension', 'retirement', 'flex', 'endowment', 'living', 'life', 'private']\n",
    "    columns_with_keywords = [column for column in df_ib_inv_contracts.columns if any(df_ib_inv_contracts[column].astype(str).str.contains('|'.join(keywords), case=False))]\n",
    "\n",
    "    # Update count_ib_inv to reflect the correct count\n",
    "    count_ib_inv = len(columns_with_keywords)\n",
    "\n",
    "    if len(columns_with_keywords) > 0:\n",
    "        first_ib_inv = re.search(r'I/B(\\d+)', columns_with_keywords[0]).group(1)\n",
    "    else:\n",
    "        first_ib_inv = \"NA\"\n",
    "\n",
    "    if len(columns_with_keywords) > 1:\n",
    "        second_ib_inv = re.search(r'I/B(\\d+)', columns_with_keywords[1]).group(1)\n",
    "    else:\n",
    "        second_ib_inv = \"NA\"\n",
    "\n",
    "    if len(columns_with_keywords) > 2:\n",
    "        third_ib_inv = re.search(r'I/B(\\d+)', columns_with_keywords[2]).group(1)\n",
    "    else:\n",
    "        third_ib_inv = \"NA\"\n",
    "    \n",
    "    inv_dict = {\n",
    "        \"first_inv\": {\"inv_no\": first_ib_inv},\n",
    "        \"second_inv\": {\"inv_no\": second_ib_inv},\n",
    "        \"third_inv\": {\"inv_no\": third_ib_inv}\n",
    "    }\n",
    "\n",
    "    # Compute max_fund_alct\n",
    "    max_fund_alct = 0\n",
    "    for inv in inv_dict.values():\n",
    "        column_index = closest_invmatch_df('I/B' + inv['inv_no'] + ':_Fund_Alc_%', df_import_pc)\n",
    "        if column_index != -1:  # Add this check to ensure we have a valid column index\n",
    "            column_name = df_import_pc.columns[column_index]\n",
    "            fund_alct_str = df_import_pc[column_name].iloc[0]\n",
    "            if pd.isnull(fund_alct_str) or fund_alct_str == 0:\n",
    "                fund_alct = 0\n",
    "            else:\n",
    "                fund_alct = fund_alct_str.count('%')\n",
    "            max_fund_alct = max(max_fund_alct, fund_alct)\n",
    "\n",
    "    # Determine inv_template\n",
    "    if count_ib_inv == 0:\n",
    "        inv_template = \"NA\"\n",
    "    elif count_ib_inv in {1, 2, 3} and max_fund_alct in {0, 1, 2, 3}:\n",
    "        inv_template = 'tbInvest' + str(count_ib_inv)\n",
    "    else:\n",
    "        inv_template = 'tbInvest3'\n",
    "\n",
    "    shInvestTemplates.range('A2').value = inv_template\n",
    "    shLists.range('I4').value = first_ib_inv\n",
    "    shLists.range('I153').value = second_ib_inv\n",
    "    shLists.range('I302').value = third_ib_inv\n",
    "    \n",
    "    return count_ib_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rc(df_import_pc):\n",
    "    df_import_pc_categories = df_import_pc.loc[:, df_import_pc.columns.str.contains('rc', case=False) & df_import_pc.columns.str.contains('category', case=False)]\n",
    "    \n",
    "    rc_dict = {}\n",
    "    rc_dict_merged = {}\n",
    "\n",
    "    for i in range(1, 9):  # looping from 1 to 8\n",
    "        key = f'{ordinal(i)}_rc'\n",
    "        field_name = f'RC{i}: Category'\n",
    "        \n",
    "        closest_match_index = closest_match_df(field_name, df_import_pc_categories)\n",
    "        closest_match_column = df_import_pc_categories.columns[closest_match_index]\n",
    "        \n",
    "        rc_no = i  # instead of extracting from closest_match_column, we use i\n",
    "        \n",
    "        category = df_import_pc_categories.iloc[0, closest_match_index]\n",
    "        \n",
    "        rc_dict[key] = {\"field_name\": field_name, \"rc_no\": rc_no, \"category\": category}\n",
    "        \n",
    "        # updating the category\n",
    "        if category is not None:\n",
    "            if 'Short Term' in category:\n",
    "                category = 'st'\n",
    "            elif any(term.lower() in category.lower() for term in ['medical', 'gap', 'health']):\n",
    "                category = 'medgap'\n",
    "            elif any(term.lower() in category.lower() for term in ['death', 'funeral', 'estate']):\n",
    "                category = 'ddc'\n",
    "        \n",
    "        rc_dict_merged[key] = {\"field_name\": field_name, \"rc_no\": rc_no, \"category\": category}\n",
    "    \n",
    "    return rc_dict_merged\n",
    "\n",
    "\n",
    "# Function to build dictionary\n",
    "def build_dictionary(data_dict, category, prefix):\n",
    "    return_dict = {}\n",
    "    return_dict[f'{prefix}'] = {}\n",
    "    count = 1\n",
    "    for k, v in data_dict.items():\n",
    "        if v['category'] == category:\n",
    "            return_dict[f'{prefix}'][f'{ordinal(count)}_{prefix}'] = v['rc_no']\n",
    "            count += 1\n",
    "    return_dict[f'{prefix}'][f'no_{prefix}'] = count-1\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "def update_df_field_list(df_tbFieldList, rc_ddc_dict, rc_st_dict, rc_medgap_dict, df_import_pc):\n",
    "    df_tb_FieldList_1st_update = df_tbFieldList.copy()\n",
    "\n",
    "    # Fill NaN values with 'TBC'\n",
    "    df_tb_FieldList_1st_update['Calculated Field Name'].fillna('TBC', inplace=True)\n",
    "\n",
    "    # iterating over each dictionary\n",
    "    for dict_obj, dict_name in [(rc_ddc_dict, 'rc_ddc'), (rc_st_dict, 'rc_st'), (rc_medgap_dict, 'rc_medgap')]:\n",
    "        for key, value in dict_obj[dict_name].items():\n",
    "            if 'no_' not in key:  # exclude the 'no_' keys\n",
    "                matching_rows = df_tb_FieldList_1st_update['Calculated Field Name'].str.contains('\\(' + key + '\\)')\n",
    "\n",
    "                # loop through matching rows and update Calculated Field Name and Result\n",
    "                for index, row in df_tb_FieldList_1st_update[matching_rows].iterrows():\n",
    "                    # updating 'Calculated Field Name'\n",
    "                    updated_field_name = row['Calculated Field Name'].replace('(' + key + ')', str(value))\n",
    "                    df_tb_FieldList_1st_update.loc[index, 'Calculated Field Name'] = updated_field_name\n",
    "                    \n",
    "                    # finding closest match in df_import_pc\n",
    "                    closest_match_index = closest_match_df(updated_field_name, df_import_pc)\n",
    "                    closest_match_column = df_import_pc.columns[closest_match_index]\n",
    "                    \n",
    "                    # updating 'Result'\n",
    "                    result_value = df_import_pc.iloc[0, closest_match_index]\n",
    "                    if pd.notna(result_value) and result_value != 0:\n",
    "                        df_tb_FieldList_1st_update.loc[index, 'Result'] = result_value\n",
    "    return df_tb_FieldList_1st_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 import df_calcs_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Extract wp from ddc\n",
    "def extract_and_manipulate_data(df):\n",
    "    # Find the rows containing the search string in the Field Description column\n",
    "    mask = df['Field Description'].str.contains('rc_wp_term', na=False)\n",
    "    \n",
    "    # Extract the corresponding values from the Result column\n",
    "    result_values = df.loc[mask, 'Result'].values\n",
    "    \n",
    "    if len(result_values) > 0:\n",
    "        # Extract wp1 and wp2 from the first matching value\n",
    "        field_value = result_values[0]\n",
    "        split_values = field_value.split('/', maxsplit=1)\n",
    "        \n",
    "        if len(split_values) > 1:\n",
    "            wp1 = split_values[1].strip()\n",
    "            wp2 = split_values[0].strip()\n",
    "            \n",
    "            # Update the Result column for the matching row\n",
    "            df.loc[mask, 'Result'] = wp1\n",
    "            \n",
    "            # Insert wp2 in the Result column offset down 1 row\n",
    "            df['Result'] = df['Result'].shift(1)\n",
    "            df.loc[mask, 'Result'] = wp2\n",
    "            \n",
    "            # Insert wp2 in the Result column offset down 2 rows\n",
    "            df['Result'] = df['Result'].shift(1)\n",
    "            df.loc[mask, 'Result'] = wp2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 convert tbFieldsList to dict_tbFieldsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Find closest match btw first PC import and dict_tbFieldsList Return dict_tbFieldsList_updated\n",
    "def update_dict_tbFieldsList(dict_tbFieldsList, df_import_pc):\n",
    "    dict_tbFieldsList_updated = dict_tbFieldsList.copy()\n",
    "\n",
    "    for item in dict_tbFieldsList_updated:\n",
    "        calculated_field_name = item['Calculated Field Name']\n",
    "        closest_match_index = closest_match_df(calculated_field_name, df_import_pc)\n",
    "\n",
    "        if closest_match_index != -1:\n",
    "            closest_match_ratio = fuzz.ratio(calculated_field_name, df_import_pc.columns[closest_match_index])\n",
    "            if closest_match_ratio > 90:\n",
    "                item['Result'] = df_import_pc.iloc[0, closest_match_index]\n",
    "    \n",
    "    return dict_tbFieldsList_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. extract calculations in ddc_dict\n",
    "def extract_and_manipulate_data(df):\n",
    "    # Find the rows containing the search string in the Field Description column\n",
    "    mask = df['Field Description'].str.contains('rc_wp_term', na=False)\n",
    "    \n",
    "    # Extract the corresponding values from the Result column\n",
    "    result_values = df.loc[mask, 'Result'].values\n",
    "    \n",
    "    if len(result_values) > 0:\n",
    "        # Extract wp1 and wp2 from the first matching value\n",
    "        field_value = result_values[0]\n",
    "        \n",
    "        # Check if the field_value is None before trying to split\n",
    "        if field_value is not None:\n",
    "            split_values = field_value.split('/', maxsplit=1)\n",
    "        \n",
    "            if len(split_values) > 1:\n",
    "                wp1 = split_values[1].strip()\n",
    "                wp2 = split_values[0].strip()\n",
    "            \n",
    "                # Update the Result column for the matching row\n",
    "                df.loc[mask, 'Result'] = wp1\n",
    "            \n",
    "                # Insert wp2 in the Result column offset down 1 row\n",
    "                df['Result'] = df['Result'].shift(1)\n",
    "                df.loc[mask, 'Result'] = wp2\n",
    "            \n",
    "                # Insert wp2 in the Result column offset down 2 rows\n",
    "                df['Result'] = df['Result'].shift(1)\n",
    "                df.loc[mask, 'Result'] = wp2\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_variables(list_of_dicts):\n",
    "    key_variables = [\"First Name\", \"Last Name\"]\n",
    "    extracted_variables = {}\n",
    "\n",
    "    for var in key_variables:\n",
    "        closest_match, result = find_closest_match(var, list_of_dicts)  # Assign returned values to two variables\n",
    "        if closest_match != 'Not Found':\n",
    "            extracted_variables[var] = result\n",
    "        else:\n",
    "            extracted_variables[var] = 'Not Found'\n",
    "\n",
    "    return extracted_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying your set_wrd_doc function to accept extracted_variables\n",
    "def set_wrd_doc(current_datetime, parent_folder, closest_folder_full_path, extracted_variables):\n",
    "    # Extracting First_Name and Last_Name from the extracted_variables dictionary\n",
    "    First_Name = extracted_variables.get(\"First Name\", \"\")\n",
    "    Last_Name = extracted_variables.get(\"Last Name\", \"\")\n",
    "\n",
    "    # Set word template\n",
    "    wrd_template = os.path.join(str(parent_folder), \"snapshot2.docm\")\n",
    "    version = 1\n",
    "    new_folder_name = f\"{Last_Name}.{First_Name}.[{Ref_No}]\"\n",
    "    new_wrd_template_filepath = os.path.join(str(closest_folder_full_path), \"snapshot\" + current_datetime + \"vs\" + str(version) + \".docm\")\n",
    "    # Check if file already exists, if yes increment the version\n",
    "    while os.path.exists(new_wrd_template_filepath):\n",
    "        version += 1\n",
    "        new_wrd_template_filepath = os.path.join(str(closest_folder_full_path), \"snapshot\" + current_datetime + \"vs\" + str(version) + \".docm\")\n",
    "    try:\n",
    "        # Copy the word template to new location\n",
    "        copyfile(wrd_template, new_wrd_template_filepath)\n",
    "    except FileNotFoundError:\n",
    "        #print(\"File not found. Please select the correct file.\")\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        wrd_template = filedialog.askopenfilename()\n",
    "        copyfile(wrd_template, new_wrd_template_filepath)\n",
    "    return new_wrd_template_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.1 Convert Transposed Dict to sheet\n",
    "\n",
    "#11.2 Write Transposed Dict to Sheet\n",
    "def apply_vars(extracted_vars, currentwb, shCalcs):\n",
    "    # Use values from extracted_vars to set values in shCalcs\n",
    "    if 'First Name' in extracted_vars:\n",
    "        shCalcs.range('A2').value = extracted_vars['First Name']\n",
    "    else:\n",
    "        print(\"First Name not found in extracted_vars\")\n",
    "        \n",
    "    if 'Last Name' in extracted_vars:\n",
    "        shCalcs.range('B2').value = extracted_vars['Last Name']\n",
    "    else:\n",
    "        print(\"Last Name not found in extracted_vars\")\n",
    "\n",
    "#11.3 Write Closest Folder to sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_wrd_doc(current_datetime, parent_folder, client_folder_path):\n",
    "    # Set word template\n",
    "    wrd_template = os.path.join(str(parent_folder), \"snapshot.docm\")\n",
    "    version = 1\n",
    "    new_wrd_template_filepath = os.path.join(str(client_folder_path), \"snapshot\" + current_datetime + \"vs\" + str(version) + \".docm\")\n",
    "\n",
    "    # Check if file already exists, if yes increment the version\n",
    "    while os.path.exists(new_wrd_template_filepath):\n",
    "        version += 1\n",
    "        new_wrd_template_filepath = os.path.join(str(client_folder_path), \"snapshot\" + current_datetime + \"vs\" + str(version) + \".docm\")\n",
    "\n",
    "\n",
    "    return new_wrd_template_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Convert df to dict\n",
    "\n",
    "def convert_df_to_dict(df, dict_tbFieldsList_updated, extracted_vars, currentwb, shLists, shCalcs, shStart):\n",
    "    df_dict = df.to_dict(orient='records')\n",
    "\n",
    "    values = [item['Result'] for item in dict_tbFieldsList_updated]\n",
    "    transposed_values = np.transpose([values])\n",
    "    shLists.range('M3').value = transposed_values\n",
    "    apply_vars(extracted_vars, currentwb, shCalcs)\n",
    "    Ref_No = shStart.range('A2').value\n",
    "\n",
    "    return df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main\n",
    "def snapshot_primary():\n",
    "    # 1: Create New Exc+Wrd Templates + Import workbooks / sheets / dataframes\n",
    "    current_datetime, shUserMapping, parent_folder, shhdr_col_static, df_hdr_col_static, df_tb_calc_pc, df_import_pc, currentwb, shcalcs_pc, shCalcs, shLists, shDDCTemplates, shInvestTemplates, shSTTemplates, shMedGapTemplates, shStart, tbTemplList, tbFieldList, df_tbTemplList, df_tbFieldList = defineshtb()\n",
    "\n",
    "    #1.2\n",
    "    Ref_No, folder_prefix, user_word_template, folder_1_suffix, folder_2_suffix, folder_3_suffix = defineusermapping(shUserMapping, currentwb, shStart, shCalcs)\n",
    "    \n",
    "    # 2: Extract ddc data + write 1-8 ddc + ddc_templ to sheets\n",
    "    count_Death_in_rows, columns_with_death, ddc_dict, has_income_protection, ddc_template = No_of_Contracts(df_import_pc, currentwb, shDDCTemplates, shLists)\n",
    "\n",
    "    # 3.1.2: Extract inv data + write 1-8 inv + inv_templ to sheets\n",
    "    #count_ib_inv, columns_with_keywords, inv_dict, max_fund_alct, inv_template = no_inv_contracts(df_import_pc, currentwb, shInvestTemplates, shLists)\n",
    "    #print(count_ib_inv, columns_with_keywords, inv_dict, max_fund_alct, inv_template)\n",
    "\n",
    "    # 4: Import Calc_pc + Create Calc_import_pc + convert to dict + replace all \":+ \"\n",
    "    df_calc_pc = shCalcs.range(\"A1\").options(pd.DataFrame, expand=\"table\").value\n",
    "\n",
    "    # 5: Extract ddc calc data + write 1-8 ddc calc to sheets\n",
    "    df_tbFieldList = extract_and_manipulate_data(df_tbFieldList)\n",
    "\n",
    "    # 6: Update dict_tbFieldsList and remove text between brackets using regular expression in update_dict_tbFieldsList\n",
    "    # In your main function replace step 6 with:\n",
    "\n",
    "    # 6: Update dict_tbFieldsList and remove text between brackets using regular expression in update_dict_tbFieldsList\n",
    "    df_import_pc_processed = remove_text_in_brackets(df_import_pc)\n",
    "\n",
    "    # 7 Convert df_tbFieldList to dict\n",
    "    dict_tbFieldsList = df_tbFieldList.to_dict('records')\n",
    "    \n",
    "    # 8: Get Unique_values are the keys in your dict_tbFieldsList_updated\n",
    "    dict_tbFieldsList_updated = update_dict_tbFieldsList(dict_tbFieldsList, df_import_pc_processed)\n",
    "    #print(dict_tbFieldsList_updated)\n",
    "\n",
    "    # 9: Process ddc_dict\n",
    "    processed_ddc_dict = process_ddc_dict(ddc_dict, df_import_pc_processed)\n",
    "    #processed_ddc_dict) \n",
    "    \n",
    "    # 10: Extract Key Variables\n",
    "    extracted_variables = extract_key_variables(dict_tbFieldsList_updated)\n",
    "\n",
    "    # 11: Convert df_import_pc to dictionary and perform additional tasks\n",
    "    df_import_pc_dict = convert_df_to_dict(df_import_pc_processed, dict_tbFieldsList_updated, extracted_variables, currentwb, shLists, shCalcs, shStart)\n",
    "\n",
    "    # Extract First_Name and Last_Name from extracted_variables\n",
    "    First_Name = extracted_variables.get(\"First Name\", \"\")\n",
    "    Last_Name = extracted_variables.get(\"Last Name\", \"\")\n",
    "    \n",
    "    # 12: Find or Create Folder\n",
    "    client_folder_path = find_or_create_folder(Last_Name, First_Name, Ref_No, folder_prefix, folder_1_suffix, folder_2_suffix, folder_3_suffix)\n",
    "\n",
    "    # 13: Set word template    \n",
    "    new_wrd_template_filepath = set_wrd_doc(current_datetime, parent_folder, client_folder_path)\n",
    "    # Set the string value of the word template filepath\n",
    "    shCalcs.range('F2').value = new_wrd_template_filepath    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "def testing():\n",
    "    # 1: Create New Exc+Wrd Templates + Import workbooks / sheets / dataframes\n",
    "    current_datetime, shUserMapping, parent_folder, shhdr_col_static, df_hdr_col_static, df_tb_calc_pc, df_import_pc, currentwb, shcalcs_pc, shCalcs, shLists, shDDCTemplates, shInvestTemplates, shSTTemplates, shMedGapTemplates, shStart, tbTemplList, tbFieldList, df_tbTemplList, df_tbFieldList = defineshtb()\n",
    "    #print(df_import_pc.head())  \n",
    "    rc_dict_merged = calc_rc(df_import_pc)\n",
    "\n",
    "    rc_ddc_dict = build_dictionary(rc_dict_merged, 'ddc', 'rc_ddc')\n",
    "    rc_medgap_dict = build_dictionary(rc_dict_merged, 'medgap', 'rc_medgap')\n",
    "    rc_st_dict = build_dictionary(rc_dict_merged, 'st', 'rc_st')\n",
    "    \n",
    "    print(rc_dict_merged)\n",
    "    print(rc_ddc_dict)\n",
    "    print(rc_medgap_dict)\n",
    "    print(rc_st_dict)\n",
    "    \n",
    "    df_tb_FieldList_1st_update = update_df_field_list(df_tbFieldList, rc_ddc_dict, rc_st_dict, rc_medgap_dict, df_import_pc)\n",
    "    print(df_tb_FieldList_1st_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1st_rc': {'field_name': 'RC1: Category', 'rc_no': 1, 'category': 'ddc'}, '2nd_rc': {'field_name': 'RC2: Category', 'rc_no': 2, 'category': 'ddc'}, '3rd_rc': {'field_name': 'RC3: Category', 'rc_no': 3, 'category': 'ddc'}, '4th_rc': {'field_name': 'RC4: Category', 'rc_no': 4, 'category': 'st'}, '5th_rc': {'field_name': 'RC5: Category', 'rc_no': 5, 'category': 'st'}, '6th_rc': {'field_name': 'RC6: Category', 'rc_no': 6, 'category': 'medgap'}, '7th_rc': {'field_name': 'RC7: Category', 'rc_no': 7, 'category': 'medgap'}, '8th_rc': {'field_name': 'RC8: Category', 'rc_no': 8, 'category': None}}\n",
      "{'rc_ddc': {'1st_rc_ddc': 1, '2nd_rc_ddc': 2, '3rd_rc_ddc': 3, 'no_rc_ddc': 3}}\n",
      "{'rc_medgap': {'1st_rc_medgap': 6, '2nd_rc_medgap': 7, 'no_rc_medgap': 2}}\n",
      "{'rc_st': {'1st_rc_st': 4, '2nd_rc_st': 5, 'no_rc_st': 2}}\n",
      "         2              Field Description  Calculated Field Name  Source  \\\n",
      "0      1.0             1st_rc_ddc_company            RC1:Company  Import   \n",
      "1      1.0               1st_rc_ddc_death             RC1: Death  Import   \n",
      "2     None              1st_rc_st_company           RC4: Company  Import   \n",
      "3     None  1st_rc_ddc_capital_disability           RC4: Company  Import   \n",
      "4     None   1st_rc_ddc_:Critical Illness  RC4: Critical Illness  Import   \n",
      "...    ...                            ...                    ...     ...   \n",
      "1207  None               3rd_ib_funds_all        I/B2_Fund_Alc_%    None   \n",
      "1208  None               4th_ib_funds_all         I/B_Fund_Alc_%    None   \n",
      "1209  None               5th_ib_funds_all         I/B_Fund_Alc_%    None   \n",
      "1210  None               6th_ib_funds_all         I/B_Fund_Alc_%    None   \n",
      "1211  None               7th_ib_funds_all         I/B_Fund_Alc_%    None   \n",
      "\n",
      "          Result  \n",
      "0       Momentum  \n",
      "1      4620041.0  \n",
      "2     Allan Gray  \n",
      "3     Allan Gray  \n",
      "4             NA  \n",
      "...          ...  \n",
      "1207        None  \n",
      "1208        None  \n",
      "1209        None  \n",
      "1210        None  \n",
      "1211        None  \n",
      "\n",
      "[1212 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "testing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
